{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance measurements of SMLT from Existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library packages\n",
    "import pandas as p\n",
    "import numpy as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datae = p.read_csv(\"heart.csv\")\n",
    "df=datae.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
    "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='target', axis=1)\n",
    "#Response variable\n",
    "y = df.loc[:,'target']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Logistic Regression Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        41\n",
      "           1       0.88      0.88      0.88        50\n",
      "\n",
      "    accuracy                           0.87        91\n",
      "   macro avg       0.87      0.87      0.87        91\n",
      "weighted avg       0.87      0.87      0.87        91\n",
      "\n",
      "Accuracy result of Logistic Regression is: 86.81318681318682\n",
      "\n",
      "Confusion Matrix result of Logistic Regression is:\n",
      " [[35  6]\n",
      " [ 6 44]]\n",
      "\n",
      "Sensitivity :  0.8536585365853658\n",
      "\n",
      "Specificity :  0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logR= LogisticRegression()\n",
    "\n",
    "logR.fit(X_train,y_train)\n",
    "\n",
    "predictR = logR.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Logistic Regression Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "xl = (accuracy_score(y_test,predictR)*100)\n",
    "\n",
    "print('Accuracy result of Logistic Regression is:', xl)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Logistic Regression is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Decision Tree Classifier Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75        41\n",
      "           1       0.82      0.72      0.77        50\n",
      "\n",
      "    accuracy                           0.76        91\n",
      "   macro avg       0.76      0.76      0.76        91\n",
      "weighted avg       0.77      0.76      0.76        91\n",
      "\n",
      "Accuracy result of Decision Tree Classifier is 75.82417582417582\n",
      "\n",
      "Confusion Matrix result of Decision Tree Classifier is:\n",
      " [[33  8]\n",
      " [14 36]]\n",
      "\n",
      "Sensitivity :  0.8048780487804879\n",
      "\n",
      "Specificity :  0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "predictDT = dtree.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Decision Tree Classifier Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictDT))\n",
    "xd = (accuracy_score(y_test,predictDT)*100)\n",
    "\n",
    "print('Accuracy result of Decision Tree Classifier is', xd)\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predictDT)\n",
    "print('Confusion Matrix result of Decision Tree Classifier is:\\n', confusion_matrix(y_test,predictDT))\n",
    "print(\"\")\n",
    "\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Random Forest Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        41\n",
      "           1       0.84      0.84      0.84        50\n",
      "\n",
      "    accuracy                           0.82        91\n",
      "   macro avg       0.82      0.82      0.82        91\n",
      "weighted avg       0.82      0.82      0.82        91\n",
      "\n",
      "Accuracy result of Random Forest is: 82.41758241758241\n",
      "\n",
      "Confusion Matrix result of Random Forest is:\n",
      " [[33  8]\n",
      " [ 8 42]]\n",
      "\n",
      "Sensitivity :  0.8048780487804879\n",
      "\n",
      "Specificity :  0.84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "predictR = rfc.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Random Forest Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "xr = (accuracy_score(y_test,predictR)*100)\n",
    "\n",
    "print('Accuracy result of Random Forest is:', xr)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Random Forest is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Support Vector Machines Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        41\n",
      "           1       0.55      1.00      0.71        50\n",
      "\n",
      "    accuracy                           0.55        91\n",
      "   macro avg       0.27      0.50      0.35        91\n",
      "weighted avg       0.30      0.55      0.39        91\n",
      "\n",
      "Accuracy result of Support Vector Machines is: 54.94505494505495\n",
      "\n",
      "Confusion Matrix result of Support Vector Machines is:\n",
      " [[ 0 41]\n",
      " [ 0 50]]\n",
      "\n",
      "Sensitivity :  0.0\n",
      "\n",
      "Specificity :  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "s = SVC()\n",
    "\n",
    "s.fit(X_train,y_train)\n",
    "\n",
    "predicts = s.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Support Vector Machines Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predicts))\n",
    "xs = (accuracy_score(y_test,predicts)*100)\n",
    "\n",
    "print('Accuracy result of Support Vector Machines is:', xs)\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predicts)\n",
    "print('Confusion Matrix result of Support Vector Machines is:\\n',cm2)\n",
    "print(\"\")\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Naive Bayes Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79        41\n",
      "           1       0.82      0.84      0.83        50\n",
      "\n",
      "    accuracy                           0.81        91\n",
      "   macro avg       0.81      0.81      0.81        91\n",
      "weighted avg       0.81      0.81      0.81        91\n",
      "\n",
      "Accuracy result of Naive Bayes is: 81.31868131868131\n",
      "\n",
      "Confusion Matrix result of Naive Bayes is:\n",
      " [[32  9]\n",
      " [ 8 42]]\n",
      "\n",
      "Sensitivity :  0.7804878048780488\n",
      "\n",
      "Specificity :  0.84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train,y_train)\n",
    "\n",
    "predictR = gnb.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Naive Bayes Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "xn = (accuracy_score(y_test,predictR)*100)\n",
    "\n",
    "print('Accuracy result of Naive Bayes is:', xn)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Naive Bayes is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of K-Nearest Neighbor Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61        41\n",
      "           1       0.68      0.72      0.70        50\n",
      "\n",
      "    accuracy                           0.66        91\n",
      "   macro avg       0.66      0.65      0.65        91\n",
      "weighted avg       0.66      0.66      0.66        91\n",
      "\n",
      "Accuracy result of K-Nearest Neighbor is: 65.93406593406593\n",
      "\n",
      "Confusion Matrix result of K-Nearest Neighbor is:\n",
      " [[24 17]\n",
      " [14 36]]\n",
      "\n",
      "Sensitivity :  0.5853658536585366\n",
      "\n",
      "Specificity :  0.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnc = KNeighborsClassifier()\n",
    "\n",
    "knnc.fit(X_train,y_train)\n",
    "\n",
    "predictR = knnc.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of K-Nearest Neighbor Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "xk = (accuracy_score(y_test,predictR)*100)\n",
    "\n",
    "print('Accuracy result of K-Nearest Neighbor is:', xk)\n",
    "print(\"\")\n",
    "cm2=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of K-Nearest Neighbor is:\\n',cm2)\n",
    "print(\"\")\n",
    "sensitivity1 = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph():\n",
    "    import matplotlib.pyplot as plt\n",
    "    data=[xl,xd,xr,xs,xn,xk]\n",
    "    alg=\"LR\",\"DT\",\"RF\",\"SVM\",\"NB\",\"KNN\"\n",
    "    plt.figure(figsize=(10,5))\n",
    "    b=plt.bar(alg,data,color=(\"r\",\"g\",\"b\",\"y\",\"m\",\"black\"))\n",
    "    plt.title(\"Heart disease of Accuracy score for Existing Datas\",fontsize=15)\n",
    "    plt.legend(b,data,fontsize=12)\n",
    "    plt.savefig('Existing.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, NavigationToolbar2Tk)\n",
    "from matplotlib.backend_bases import key_press_handler\n",
    "from matplotlib.figure import Figure\n",
    "import numpy as np\n",
    "root = tkinter.Tk()\n",
    "root.wm_title(\"Heart disease of Accuracy score for Existing Datas\")\n",
    "fig = Figure(figsize=(10,10),dpi=1)\n",
    "canvas = FigureCanvasTkAgg(fig, master=root)  \n",
    "canvas.draw()\n",
    "canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "icon=tkinter.PhotoImage(file='Existing.png')   \n",
    "label=tkinter.Label(root,image=icon)\n",
    "label.pack()\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
